region_names <- ddply(data, .(data$region_ID, data$Region), nrow)
region_names <- region_names[, c('data$region_ID', 'data$Region')]
region_names
#write.csv(region_names, 'region_id.csv')
data_period <- c('2019-01-01', '2019-11-23')
head(data)
mm <- best_matches(data = data,
id_variable = "region_ID",
date_variable = "Day",
matching_variable = "Signups",
parallel = TRUE,
warping_limit = 1,
dtw_emphasis = 1, #setting dtw_emphasis to 1 ensures scores are output- no impact to chosen control
matches = length(unique(data$Region)), # retrieve scores for all markets for each market
start_match_period = data_period[1],
end_match_period = data_period[2])
head(mm$BestMatches)
mm <- merge(x=mm$BestMatches, y=region_names, by.x='region_ID', by.y='data$region_ID', all.x=TRUE)
mm <- mm[, c('region_ID', 'BestControl', 'RelativeDistance', 'Correlation', 'rank', 'data$Region')]
colnames(mm)[colnames(mm) == 'data$Region'] <- 'Region'
mm <- merge(x=mm, y=region_names, by.x='BestControl', by.y='data$region_ID', all.x=TRUE)
colnames(mm)[colnames(mm) == 'data$Region'] <- 'ComparedRegion'
head(mm)
mm <- mm[order(mm$Region, mm$rank),]
head(mm)
write.csv(mm, 'MM_results.csv', row.names=FALSE)
###user input
setwd("C:/Users/charles.tan/Documents/GitHub/Essence_stuff/Q120 YTP") #set working directory
###
#import libaries
libs <- c("zoo",
"dtw",
"MarketMatching",
"Rcpp",
"CausalImpact",
"lubridate",
"tidyverse",
"ggplot2",
"reshape2",
"plyr",
"pivottabler",
"dplyr",
"GeoexperimentsResearch")
for (lib in libs) {
if (!require(lib, character.only = TRUE)) {
install.packages(lib)
require(lib, character.only = TRUE)
}
}
#if installing GeoexperimentsResearch fails, run the code below
#install.packages("githubinstall")
#library(githubinstall)
#githubinstall("GeoexperimentsResearch")
#library(GeoexperimentsResearch)
data_raw = read.csv('signups.csv', header=T, encoding='UTF-8')
colnames(data_raw)[1] <- 'Day'
print(head(data_raw))
data_raw$Day <- as.Date(data_raw$Day, format="%Y-%m-%d")
data <- data_raw[complete.cases(data_raw), ]
data <- data[order(data$Region), ]
data$region_ID <- cumsum(!duplicated(data$Region))
region_names <- ddply(data, .(data$region_ID, data$Region), nrow)
region_names <- region_names[, c('data$region_ID', 'data$Region')]
region_names
#write.csv(region_names, 'region_id.csv')
data_period <- c('2019-11-23', '2019-11-23')
head(data)
mm <- best_matches(data = data,
id_variable = "region_ID",
date_variable = "Day",
matching_variable = "Signups",
parallel = TRUE,
warping_limit = 1,
dtw_emphasis = 1, #setting dtw_emphasis to 1 ensures scores are output- no impact to chosen control
matches = length(unique(data$Region)), # retrieve scores for all markets for each market
start_match_period = data_period[1],
end_match_period = data_period[2])
head(mm$BestMatches)
mm <- merge(x=mm$BestMatches, y=region_names, by.x='region_ID', by.y='data$region_ID', all.x=TRUE)
mm <- mm[, c('region_ID', 'BestControl', 'RelativeDistance', 'Correlation', 'rank', 'data$Region')]
colnames(mm)[colnames(mm) == 'data$Region'] <- 'Region'
mm <- merge(x=mm, y=region_names, by.x='BestControl', by.y='data$region_ID', all.x=TRUE)
colnames(mm)[colnames(mm) == 'data$Region'] <- 'ComparedRegion'
head(mm)
mm <- mm[order(mm$Region, mm$rank),]
head(mm)
write.csv(mm, 'MM_results.csv', row.names=FALSE)
###user input
setwd("C:/Users/charles.tan/Documents/GitHub/Essence_stuff/Q120 YTP") #set working directory
###
#import libaries
libs <- c("zoo",
"dtw",
"MarketMatching",
"Rcpp",
"CausalImpact",
"lubridate",
"tidyverse",
"ggplot2",
"reshape2",
"plyr",
"pivottabler",
"dplyr",
"GeoexperimentsResearch")
for (lib in libs) {
if (!require(lib, character.only = TRUE)) {
install.packages(lib)
require(lib, character.only = TRUE)
}
}
#if installing GeoexperimentsResearch fails, run the code below
#install.packages("githubinstall")
#library(githubinstall)
#githubinstall("GeoexperimentsResearch")
#library(GeoexperimentsResearch)
data_raw = read.csv('signups.csv', header=T, encoding='UTF-8')
colnames(data_raw)[1] <- 'Day'
print(head(data_raw))
data_raw$Day <- as.Date(data_raw$Day, format="%Y-%m-%d")
data <- data_raw[complete.cases(data_raw), ]
data <- data[order(data$Region), ]
data$region_ID <- cumsum(!duplicated(data$Region))
region_names <- ddply(data, .(data$region_ID, data$Region), nrow)
region_names <- region_names[, c('data$region_ID', 'data$Region')]
region_names
#write.csv(region_names, 'region_id.csv')
data_period <- c('2019-11-23', '2019-11-23')
head(data)
mm <- best_matches(data = data,
id_variable = "region_ID",
date_variable = "Day",
matching_variable = "Signups",
parallel = TRUE,
warping_limit = 1,
dtw_emphasis = 1, #setting dtw_emphasis to 1 ensures scores are output- no impact to chosen control
matches = length(unique(data$Region)), # retrieve scores for all markets for each market
start_match_period = data_period[1],
end_match_period = data_period[2])
head(mm$BestMatches)
mm <- merge(x=mm$BestMatches, y=region_names, by.x='region_ID', by.y='data$region_ID', all.x=TRUE)
mm <- mm[, c('region_ID', 'BestControl', 'RelativeDistance', 'Correlation', 'rank', 'data$Region')]
colnames(mm)[colnames(mm) == 'data$Region'] <- 'Region'
mm <- merge(x=mm, y=region_names, by.x='BestControl', by.y='data$region_ID', all.x=TRUE)
colnames(mm)[colnames(mm) == 'data$Region'] <- 'ComparedRegion'
head(mm)
mm <- mm[order(mm$Region, mm$rank),]
head(mm)
write.csv(mm, 'MM_results.csv', row.names=FALSE)
orkflow Documentation:
#Market Selection:
#1. From Time-series Data and a single KPI, we select candidates for control holdout based on the following priorities
#- Top 30 percentile lowest dtw distance scores across all geos considered
#- Correlation of >90%
#- Correlation with Population >50%
#2. Within these constraints, we select 2 or more exposed markets with the highest number of shared control holdouts possible (recommended 5-20 control regions, but minimally 3 control markets in countries where control regions may be limited)
#Control Market Validation:
#1. To safeguard against false positive from control selection error - Segment the pre-period data into a 2 : 1 ratio and run Causal Impact at 90% significance - there should be no significant lift
#Inputs requirements:
#1. Daily time-series data for KPI variable/conversions (segmented by geo)
#- e.g. Day, Region, Signups
#2. Minimum 90 day period for pre-period data
#3. Post-period analysed should minimally follow a 1:2 ratio with pre-period data input
#Variables that require user inputs have been commented with ###user input. Ctrl+F to see.
###########################################
###user input
setwd("C:/Users/charles.tan/Documents/GitHub/Essence_stuff/Q120 YTP") #set working directory
###
#import libaries
libs <- c("zoo",
"dtw",
"MarketMatching",
"Rcpp",
"CausalImpact",
"lubridate",
"tidyverse",
"ggplot2",
"reshape2",
"plyr",
"pivottabler",
"dplyr",
"GeoexperimentsResearch")
for (lib in libs) {
if (!require(lib, character.only = TRUE)) {
install.packages(lib)
require(lib, character.only = TRUE)
}
}
#if installing GeoexperimentsResearch fails, run the code below
#install.packages("githubinstall")
#library(githubinstall)
#githubinstall("GeoexperimentsResearch")
#library(GeoexperimentsResearch)
data_raw = read.csv('signups.csv', header=T, encoding='UTF-8')
colnames(data_raw)[1] <- 'Day'
print(head(data_raw))
data_raw$Day <- as.Date(data_raw$Day, format="%Y-%m-%d")
data <- data_raw[complete.cases(data_raw), ]
data <- data[order(data$Region), ]
data$region_ID <- cumsum(!duplicated(data$Region))
region_names <- ddply(data, .(data$region_ID, data$Region), nrow)
region_names <- region_names[, c('data$region_ID', 'data$Region')]
region_names
#write.csv(region_names, 'region_id.csv')
data_period <- c('2018-11-23', '2019-11-23')
head(data)
mm <- best_matches(data = data,
id_variable = "region_ID",
date_variable = "Day",
matching_variable = "Signups",
parallel = TRUE,
warping_limit = 1,
dtw_emphasis = 1, #setting dtw_emphasis to 1 ensures scores are output- no impact to chosen control
matches = length(unique(data$Region)), # retrieve scores for all markets for each market
start_match_period = data_period[1],
end_match_period = data_period[2])
head(mm$BestMatches)
mm <- merge(x=mm$BestMatches, y=region_names, by.x='region_ID', by.y='data$region_ID', all.x=TRUE)
mm <- mm[, c('region_ID', 'BestControl', 'RelativeDistance', 'Correlation', 'rank', 'data$Region')]
colnames(mm)[colnames(mm) == 'data$Region'] <- 'Region'
mm <- merge(x=mm, y=region_names, by.x='BestControl', by.y='data$region_ID', all.x=TRUE)
colnames(mm)[colnames(mm) == 'data$Region'] <- 'ComparedRegion'
head(mm)
mm <- mm[order(mm$Region, mm$rank),]
head(mm)
write.csv(mm, 'MM_results.csv', row.names=FALSE)
##user input
setwd("C:/Users/charles.tan/Documents/GitHub/Essence_stuff/Q120 YTP") #set working directory
###
#import libaries
libs <- c("zoo",
"dtw",
"MarketMatching",
"Rcpp",
"CausalImpact",
"lubridate",
"tidyverse",
"ggplot2",
"reshape2",
"plyr",
"pivottabler",
"dplyr",
"GeoexperimentsResearch")
for (lib in libs) {
if (!require(lib, character.only = TRUE)) {
install.packages(lib)
require(lib, character.only = TRUE)
}
}
#if installing GeoexperimentsResearch fails, run the code below
#install.packages("githubinstall")
#library(githubinstall)
#githubinstall("GeoexperimentsResearch")
#library(GeoexperimentsResearch)
#data_raw = read.csv('signups.csv', header=T, encoding='UTF-8')
data_raw = read.csv('signups_agg_control.csv', header=T, encoding='UTF-8')
colnames(data_raw)[1] <- 'Day'
print(head(data_raw))
data_raw$Day <- as.Date(data_raw$Day, format="%Y-%m-%d")
data <- data_raw[complete.cases(data_raw), ]
data <- data[order(data$Region), ]
data$region_ID <- cumsum(!duplicated(data$Region))
region_names <- ddply(data, .(data$region_ID, data$Region), nrow)
region_names <- region_names[, c('data$region_ID', 'data$Region')]
region_names
#write.csv(region_names, 'region_id.csv')
data_period <- c('2018-11-23', '2019-11-23')
head(data)
mm <- best_matches(data = data,
id_variable = "region_ID",
date_variable = "Day",
matching_variable = "Signups",
parallel = TRUE,
warping_limit = 1,
dtw_emphasis = 1, #setting dtw_emphasis to 1 ensures scores are output- no impact to chosen control
matches = length(unique(data$Region)), # retrieve scores for all markets for each market
start_match_period = data_period[1],
end_match_period = data_period[2])
head(mm$BestMatches)
mm <- merge(x=mm$BestMatches, y=region_names, by.x='region_ID', by.y='data$region_ID', all.x=TRUE)
mm <- mm[, c('region_ID', 'BestControl', 'RelativeDistance', 'Correlation', 'rank', 'data$Region')]
colnames(mm)[colnames(mm) == 'data$Region'] <- 'Region'
mm <- merge(x=mm, y=region_names, by.x='BestControl', by.y='data$region_ID', all.x=TRUE)
colnames(mm)[colnames(mm) == 'data$Region'] <- 'ComparedRegion'
head(mm)
mm <- mm[order(mm$Region, mm$rank),]
head(mm)
write.csv(mm, 'MM_results.csv', row.names=FALSE)
input
setwd("C:/Users/charles.tan/Documents/GitHub/Essence_stuff/Q120 YTP") #set working directory
###
#import libaries
libs <- c("zoo",
"dtw",
"MarketMatching",
"Rcpp",
"CausalImpact",
"lubridate",
"tidyverse",
"ggplot2",
"reshape2",
"plyr",
"pivottabler",
"dplyr",
"GeoexperimentsResearch")
for (lib in libs) {
if (!require(lib, character.only = TRUE)) {
install.packages(lib)
require(lib, character.only = TRUE)
}
}
#if installing GeoexperimentsResearch fails, run the code below
#install.packages("githubinstall")
#library(githubinstall)
#githubinstall("GeoexperimentsResearch")
#library(GeoexperimentsResearch)
data_raw = read.csv('signups.csv', header=T, encoding='UTF-8')
#data_raw = read.csv('signups_agg_control.csv', header=T, encoding='UTF-8')
colnames(data_raw)[1] <- 'Day'
print(head(data_raw))
data_raw$Day <- as.Date(data_raw$Day, format="%Y-%m-%d")
data <- data_raw[complete.cases(data_raw), ]
data <- data[order(data$Region), ]
data$region_ID <- cumsum(!duplicated(data$Region))
region_names <- ddply(data, .(data$region_ID, data$Region), nrow)
region_names <- region_names[, c('data$region_ID', 'data$Region')]
region_names
#write.csv(region_names, 'region_id.csv')
data_period <- c('2018-11-23', '2019-11-23')
head(data)
mm <- best_matches(data = data,
id_variable = "region_ID",
date_variable = "Day",
matching_variable = "Signups",
parallel = TRUE,
warping_limit = 1,
dtw_emphasis = 1, #setting dtw_emphasis to 1 ensures scores are output- no impact to chosen control
matches = length(unique(data$Region)), # retrieve scores for all markets for each market
start_match_period = data_period[1],
end_match_period = data_period[2])
head(mm$BestMatches)
mm <- merge(x=mm$BestMatches, y=region_names, by.x='region_ID', by.y='data$region_ID', all.x=TRUE)
mm <- mm[, c('region_ID', 'BestControl', 'RelativeDistance', 'Correlation', 'rank', 'data$Region')]
colnames(mm)[colnames(mm) == 'data$Region'] <- 'Region'
mm <- merge(x=mm, y=region_names, by.x='BestControl', by.y='data$region_ID', all.x=TRUE)
colnames(mm)[colnames(mm) == 'data$Region'] <- 'ComparedRegion'
head(mm)
mm <- mm[order(mm$Region, mm$rank),]
head(mm)
write.csv(mm, 'MM_results.csv', row.names=FALSE)
#write.csv(mm, 'MM_results_agg_control.csv', row.names=FALSE)
##user input
setwd("C:/Users/charles.tan/Documents/GitHub/Essence_stuff/Q120 YTP") #set working directory
###
#import libaries
libs <- c("zoo",
"dtw",
"MarketMatching",
"Rcpp",
"CausalImpact",
"lubridate",
"tidyverse",
"ggplot2",
"reshape2",
"plyr",
"pivottabler",
"dplyr",
"GeoexperimentsResearch")
for (lib in libs) {
if (!require(lib, character.only = TRUE)) {
install.packages(lib)
require(lib, character.only = TRUE)
}
}
#if installing GeoexperimentsResearch fails, run the code below
#install.packages("githubinstall")
#library(githubinstall)
#githubinstall("GeoexperimentsResearch")
#library(GeoexperimentsResearch)
#data_raw = read.csv('signups.csv', header=T, encoding='UTF-8')
data_raw = read.csv('signups_agg_control.csv', header=T, encoding='UTF-8')
colnames(data_raw)[1] <- 'Day'
print(head(data_raw))
data_raw$Day <- as.Date(data_raw$Day, format="%Y-%m-%d")
data <- data_raw[complete.cases(data_raw), ]
data <- data[order(data$Region), ]
data$region_ID <- cumsum(!duplicated(data$Region))
region_names <- ddply(data, .(data$region_ID, data$Region), nrow)
region_names <- region_names[, c('data$region_ID', 'data$Region')]
region_names
#write.csv(region_names, 'region_id.csv')
data_period <- c('2018-11-23', '2019-11-23')
head(data)
mm <- best_matches(data = data,
id_variable = "region_ID",
date_variable = "Day",
matching_variable = "Signups",
parallel = TRUE,
warping_limit = 1,
dtw_emphasis = 1, #setting dtw_emphasis to 1 ensures scores are output- no impact to chosen control
matches = length(unique(data$Region)), # retrieve scores for all markets for each market
start_match_period = data_period[1],
end_match_period = data_period[2])
head(mm$BestMatches)
mm <- merge(x=mm$BestMatches, y=region_names, by.x='region_ID', by.y='data$region_ID', all.x=TRUE)
mm <- mm[, c('region_ID', 'BestControl', 'RelativeDistance', 'Correlation', 'rank', 'data$Region')]
colnames(mm)[colnames(mm) == 'data$Region'] <- 'Region'
mm <- merge(x=mm, y=region_names, by.x='BestControl', by.y='data$region_ID', all.x=TRUE)
colnames(mm)[colnames(mm) == 'data$Region'] <- 'ComparedRegion'
head(mm)
mm <- mm[order(mm$Region, mm$rank),]
head(mm)
#write.csv(mm, 'MM_results.csv', row.names=FALSE)
write.csv(mm, 'MM_results_agg_control.csv', row.names=FALSE)
###user input
setwd("C:/Users/charles.tan/Documents/GitHub/Essence_stuff/Q120 YTP") #set working directory
###
#import libaries
libs <- c("zoo",
"dtw",
"MarketMatching",
"Rcpp",
"CausalImpact",
"lubridate",
"tidyverse",
"ggplot2",
"reshape2",
"plyr",
"pivottabler",
"dplyr",
"GeoexperimentsResearch")
for (lib in libs) {
if (!require(lib, character.only = TRUE)) {
install.packages(lib)
require(lib, character.only = TRUE)
}
}
#if installing GeoexperimentsResearch fails, run the code below
#install.packages("githubinstall")
#library(githubinstall)
#githubinstall("GeoexperimentsResearch")
#library(GeoexperimentsResearch)
############################################
############################################
#We are going to compare Time-based regression and CausalImpact for back-testing below.
#User needs to input the pre-test and test dates in test_period and
#the regions assigned to exposed and control in geoassign below.
#Both are done at 95% confidence level.
#In this section, we will evaluate if the methods (correctly) predict a lift or not
#when there should/ shouldn't be.
############################################
###user input
test_period = c("2019-03-01","2019-05-01","2019-05-31")
geoassign<-data.frame("geo"=c('Osaka Prefecture', 'Kanagawa Prefecture', 'Tokyo', 'Saitama Prefecture', 'Hyogo Prefecture',
'Shizuoka Prefecture', 'Kyoto Prefecture', 'Ibaraki Prefecture', 'Hiroshima Prefecture',
'Miyagi Prefecture', 'Tochigi Prefecture', 'Niigata Prefecture', 'Gunma Prefecture', 'Nagano Prefecture',
'Fukushima Prefecture', 'Gifu Prefecture', 'Okinawa Prefecture', 'Okayama Prefecture', 'Mie Prefecture',
'Kumamoto Prefecture', 'Shiga Prefecture',
'Aichi Prefecture', 'Chiba Prefecture', 'Fukuoka Prefecture', 'Hokkaido Prefecture'),
"geo.group"=c(1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2)) #set exposed and control markets
###
#Back-testing with Time-based Regression
data<-read.csv('signups.csv', header=T)
colnames(data)<-c("date","geo","Signups")
data2<-data[data$date>=test_period[1] & data$date<=test_period[3],]
head(data2)
obj.gts<-GeoTimeseries(data2,metrics=c("Signups"))
#Back-testing with Time-based Regression
data<-read.csv('signups.csv', header=T)
colnames(data)<-c("date","geo","Signups")
head(data)
data$date <- as.Date(data$date, format="%Y-%m-%d")
head(data)
data2<-data[data$date>=test_period[1] & data$date<=test_period[3],]
head(data2)
obj.gts<-GeoTimeseries(data2,metrics=c("Signups"))
head(obj.gts)
aggregate(obj.gts,by='.weekindex')
plot(obj.gts)
obj.per<-ExperimentPeriods(test_period)
obj.per
geoassign
obj.ga<-GeoAssignment(geoassign)
obj.ga
obj.gts2 <- obj.gts[obj.gts$geo %in% geoassign$geo ,]
head(obj.gts2)
obj<-GeoExperimentData(obj.gts2, periods=obj.per, geo.assignment=obj.ga)
head(obj)
aggregate(obj,by=c('period','geo.group'))
obj.tbr<-DoTBRAnalysis(obj,response="Signups",model='tbr1',
pretest.period=0,
intervention.period=1,
cooldown.period=NULL,
control.group=2,
treatment.group=1)
summary(obj.tbr)
head(obj.tbr)
plot(obj.tbr)
obj_ci<-aggregate(obj,by=c('date','geo.group'))
obj_ci
pre.period <- as.Date(c(test_period[1],toString(as.Date(test_period[2])-1)))
post.period <- as.Date(c(test_period[2],test_period[3]))
time.points <- seq.Date(as.Date(test_period[1]), by = 1, length.out = nrow(obj_ci)/2)
max(time.points)
ci_data <- zoo(cbind(obj_ci[obj_ci$geo.group==1,]$Signups, obj_ci[obj_ci$geo.group==2,]$Signups), time.points)
ci_data
impact <- CausalImpact(ci_data, pre.period, post.period, alpha = 0.05, model.args = list(niter = 5000))
plot(impact)
summary(impact)
ggplot(data=obj_ci,aes(x=date,y=Signups,group=as.factor(geo.group), colour=as.factor(geo.group)))+
geom_line()+
geom_point()
plot(impact)
