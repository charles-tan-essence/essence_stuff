#if installing GeoexperimentsResearch fails, run the code below
install.packages("githubinstall")
#library(githubinstall)
githubinstall("GeoexperimentsResearch")
library(githubinstall)
knitr::opts_chunk$set(echo = TRUE)
libs <- c("readr",
"CausalImpact",
"zoo",
"ggplot2",
"dplyr",
"stringr",
"reshape2",
"prophet",
"devtools",
"ggmap",
"maps",
"mapdata",
"sp",
"ggthemes",
"tidyr")
for (lib in libs) {
if (!require(lib, character.only = TRUE)) {
install.packages(lib)
require(lib, character.only = TRUE)
}
}
rm(lib, libs)
# file locations
data_file <- "MAU.csv"
fs_raw <- data.frame(read_csv(data_file))
#colnames(fs_raw) <- c("Date", "North_Sumatra", "West_Java", "South_Sulawesi")
#sum(colSums(fs_raw == 0))
fs_raw <- data.frame(read_csv(data_file))
fs_raw
#colnames(fs_raw) <- c("Date", "North_Sumatra", "West_Java", "South_Sulawesi")
#sum(colSums(fs_raw == 0))
fs_raw <- data.frame(read_csv(data_file))
head(fs_raw)
#colnames(fs_raw) <- c("Date", "North_Sumatra", "West_Java", "South_Sulawesi")
#sum(colSums(fs_raw == 0))
View(fs_raw)
data_file <- read.csv("DAU.csv")
colnames(data_file[1]) <- c("Date")
#colnames(data_file) <- c("Date", colnames(data_file[2:31]))
#sum(colSums(data_file == 0))
#summary(data_file)
#typeof(data_file[1])
fs_analyse <- data_file
fs_analyse$Date <- as.Date(fs_analyse$Date, "%m/%d/%Y")
start <- min(fs_analyse$Date)
#exposed_region1 <- c("Medan")
#exposed_region2 <- c("Makassar")
#control <- colnames(fs_analyse[22:31])
rownames(fs_analyse) <- fs_analyse$Date
data_file
fs_raw
fs_raw[('TH-50', 'TH-57')]
fs_raw['TH-50', 'TH-57']
############################################
#title: "Match Market Selection - YTP JP Q319"
#author: "Kenneth Koh & Hui Xiang Chua"
#date: "June 17, 2019"
#--------------------------------------------
#Objective: To maximize comparability of Match Market a standardized framework in which we evaluate causal effects using geographically segregated control holdout
#Workflow Documentation:
#Market Selection:
#1. From Time-series Data and a single KPI, we select candidates for control holdout based on the following priorities
#- Top 30 percentile lowest dtw distance scores across all geos considered
#- Correlation of >90%
#- Correlation with Population >50%
#2. Within these constraints, we select 2 or more exposed markets with the highest number of shared control holdouts possible (recommended 5-20 control regions, but minimally 3 control markets in countries where control regions may be limited)
#Control Market Validation:
#1. To safeguard against false positive from control selection error - Segment the pre-period data into a 2 : 1 ratio and run Causal Impact at 90% significance - there should be no significant lift
#Inputs requirements:
#1. Daily time-series data for KPI variable/conversions (segmented by geo)
#- e.g. Day, Region, Signups
#2. Minimum 90 day period for pre-period data
#3. Post-period analysed should minimally follow a 1:2 ratio with pre-period data input
#Variables that require user inputs have been commented with ###user input. Ctrl+F to see.
###########################################
###user input
setwd("C:/Users/huixiang.chua/Downloads") #set working directory
###
#import libaries
libs <- c("zoo",
"dtw",
"MarketMatching",
"Rcpp",
"CausalImpact",
"lubridate",
"tidyverse",
"ggplot2",
"reshape2",
"plyr",
"pivottabler",
"dplyr",
"GeoexperimentsResearch")
for (lib in libs) {
if (!require(lib, character.only = TRUE)) {
install.packages(lib)
require(lib, character.only = TRUE)
}
}
#if installing GeoexperimentsResearch fails, run the code below
#install.packages("githubinstall")
#library(githubinstall)
#githubinstall("GeoexperimentsResearch")
#library(GeoexperimentsResearch)
#read in dataset
ConversionsRaw <- read.csv("YouTube Premium_Signups_JP_Region_Nov18toJun19.csv",header=T)
ConversionsRaw <- ConversionsRaw[ , c("Day", "Region", "Signups")]
head(ConversionsRaw)
############################################
#title: "Match Market Selection - YTP JP Q319"
#author: "Kenneth Koh & Hui Xiang Chua"
#date: "June 17, 2019"
#--------------------------------------------
#Objective: To maximize comparability of Match Market a standardized framework in which we evaluate causal effects using geographically segregated control holdout
#Workflow Documentation:
#Market Selection:
#1. From Time-series Data and a single KPI, we select candidates for control holdout based on the following priorities
#- Top 30 percentile lowest dtw distance scores across all geos considered
#- Correlation of >90%
#- Correlation with Population >50%
#2. Within these constraints, we select 2 or more exposed markets with the highest number of shared control holdouts possible (recommended 5-20 control regions, but minimally 3 control markets in countries where control regions may be limited)
#Control Market Validation:
#1. To safeguard against false positive from control selection error - Segment the pre-period data into a 2 : 1 ratio and run Causal Impact at 90% significance - there should be no significant lift
#Inputs requirements:
#1. Daily time-series data for KPI variable/conversions (segmented by geo)
#- e.g. Day, Region, Signups
#2. Minimum 90 day period for pre-period data
#3. Post-period analysed should minimally follow a 1:2 ratio with pre-period data input
#Variables that require user inputs have been commented with ###user input. Ctrl+F to see.
###########################################
###user input
setwd("C:/Users/charles.tan/Documents/GitHub/Essence_stuff/Q120 YTP") #set working directory
###
#import libaries
libs <- c("zoo",
"dtw",
"MarketMatching",
"Rcpp",
"CausalImpact",
"lubridate",
"tidyverse",
"ggplot2",
"reshape2",
"plyr",
"pivottabler",
"dplyr",
"GeoexperimentsResearch")
for (lib in libs) {
if (!require(lib, character.only = TRUE)) {
install.packages(lib)
require(lib, character.only = TRUE)
}
}
#if installing GeoexperimentsResearch fails, run the code below
#install.packages("githubinstall")
#library(githubinstall)
#githubinstall("GeoexperimentsResearch")
#library(GeoexperimentsResearch)
#data_raw = read.csv('signups.csv', header=T, encoding='UTF-8')
data_raw = read.csv('signups_agg_control.csv', header=T, encoding='UTF-8')
colnames(data_raw)[1] <- 'Day'
print(head(data_raw))
